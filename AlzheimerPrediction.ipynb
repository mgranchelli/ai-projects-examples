{
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3398,
          "sourceType": "datasetVersion",
          "datasetId": 1980
        }
      ],
      "dockerImageVersionId": 46,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgranchelli/ai-projects-examples/blob/main/AlzheimerPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detecting early Alzheimer's"
      ],
      "metadata": {
        "id": "RPIBkis9u_2Q",
        "_uuid": "31aff975d245f351c6a47a411251c09cf0df142a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alzheimer's disease\n",
        "\n",
        "* [Alzheimer's disease (AD)](https://en.wikipedia.org/wiki/Alzheimer%27s_disease) is a neurodegenerative disorder of uncertain cause and pathogenesis that primarily affects older adults and is the most common cause of dementia.\n",
        "* The earliest clinical manifestation of AD is selective memory impairment and while treatments are available to ameliorate some symptoms, there is no cure currently available.\n",
        "* Brain Imaging via magnetic resonance imaging (MRI), is used for evaluation of patients with suspected AD.\n",
        "* MRI findings include both, local and generalized shrinkage of brain tissue.\n",
        "* Some studies have suggested that MRI features may predict rate of decline of AD and may guide therapy in the future.\n",
        "* However in order to reach that stage clinicians and researchers will have to make use of machine learning techniques that can accurately predict progress of a patient from mild cognitive impairment to dementia.\n",
        "* We propose to develop a sound model that can help clinicians do that and predict early alzheimer's."
      ],
      "metadata": {
        "id": "Rqz5sHwoScR7",
        "_uuid": "fedeb7d2f5ade1370c0422693aedff04d4d886f8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data description\n",
        "* We will be using the [longitudinal MRI data](http://www.oasis-brains.org/pdf/oasis_longitudinal.csv).\n",
        "* The dataset consists of a longitudinal MRI data of 150 subjects aged 60 to 96.\n",
        "* Each subject was scanned at least once.\n",
        "* Everyone is right-handed.\n",
        "* 72 of the subjects were grouped as 'Nondemented' throughout the study.\n",
        "* 64 of the subjects were grouped as 'Demented' at the time of their initial visits and remained so throughout the study.\n",
        "* 14 subjects were grouped as 'Nondemented' at the time of their initial visit and were subsequently characterized as 'Demented' at a later visit. These fall under the 'Converted' category.\n",
        "\n",
        "### Column descriptors\n",
        "\n",
        "|COL  |FULL-FORMS                          |\n",
        "|-----|------------------------------------|\n",
        "|EDUC |Years of education                  |\n",
        "|SES  |Socioeconomic Status                |\n",
        "|MMSE |Mini Mental State Examination       |\n",
        "|CDR  |Clinical Dementia Rating            |\n",
        "|eTIV |Estimated Total Intracranial Volume |\n",
        "|nWBV |Normalize Whole Brain Volume        |\n",
        "|ASF  |Atlas Scaling Factor                |\n"
      ],
      "metadata": {
        "id": "FG0zBhPkScR7",
        "_uuid": "6fe31a2ec5929f28eff868ae06f907daeb26fb5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data"
      ],
      "metadata": {
        "id": "3-gJj11NNnrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown -q"
      ],
      "metadata": {
        "id": "u16J38Z1Nsd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=10mXHToPKkOcWlNzOmigVnthr3yyoNsfa"
      ],
      "metadata": {
        "id": "bdT-UsI5Nvve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q alzheimers-data.zip"
      ],
      "metadata": {
        "id": "Ep-NJUdCNyOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import library"
      ],
      "metadata": {
        "id": "NZY1X2InOhOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "_uuid": "6a720755860b07d7eb93e458306ec1b6fa079ed5",
        "id": "krqlSLMJB3_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "K7EFKo4yEICP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('alzheimers-data/oasis_longitudinal.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "YKxtNjSHEJct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "4R_ioTLb-zWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.loc[df['Visit']==1] # use first visit data only because of the analysis we're doing\n",
        "df = df.reset_index(drop=True) # reset index after filtering first visit data\n",
        "df['M/F'] = df['M/F'].replace(['F','M'], [0,1]) # M/F column\n",
        "df['Group'] = df['Group'].replace(['Converted'], ['Demented']) # Target variable\n",
        "df['Group'] = df['Group'].replace(['Demented', 'Nondemented'], [1,0]) # Target variable\n",
        "df = df.drop(['MRI ID', 'Visit', 'Hand'], axis=1) # Drop unnecessary columns"
      ],
      "metadata": {
        "_uuid": "08991ab4c6c3aef89ad366662aad97a846aa9d8f",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "tHAc44CFB3_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bar drawing function\n",
        "def bar_chart(feature):\n",
        "    Demented = df[df['Group']==1][feature].value_counts()\n",
        "    Nondemented = df[df['Group']==0][feature].value_counts()\n",
        "    df_bar = pd.DataFrame([Demented,Nondemented])\n",
        "    df_bar.index = ['Demented','Nondemented']\n",
        "    df_bar.plot(kind='bar',stacked=True, figsize=(8,5))"
      ],
      "metadata": {
        "id": "-4-ZVrHJslSF",
        "_uuid": "9175b97a0b02ff8ace2e3bc8a6327488b3232783",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gender  and  Group (Femal=0, Male=1)\n",
        "bar_chart('M/F')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Number of patients')\n",
        "plt.legend()\n",
        "plt.title('Gender and Demented rate')"
      ],
      "metadata": {
        "id": "k-92eJ7pslSL",
        "_uuid": "5f8599d4f70b78047011217e3bbcaa26311fddc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above graph indicates that men are more likely with dementia than women."
      ],
      "metadata": {
        "id": "9m16iCGyslSO",
        "_uuid": "46c3ccb6893e52a6636e9a764539a92084f90407"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MMSE : Mini Mental State Examination\n",
        "# Nondemented = 0, Demented =1\n",
        "# Nondemented has higher test result ranging from 25 to 30.\n",
        "#Min 17 ,MAX 30\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'MMSE',fill= True)\n",
        "facet.set(xlim=(0, df['MMSE'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(15.30)"
      ],
      "metadata": {
        "id": "QfZMuTl7slSP",
        "_uuid": "e1b8fbe86bbf469971aed915c2b8e9caa9cdbe53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows Nondemented group got much more higher MMSE scores than Demented group."
      ],
      "metadata": {
        "id": "WumyA7d6slSR",
        "_uuid": "8d01f7c6b66442f0b1eeb814464cec8654a24945"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bar_chart('ASF') = Atlas Scaling Factor\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'ASF',fill= True)\n",
        "facet.set(xlim=(0, df['ASF'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(0.5, 2)\n",
        "\n",
        "#eTIV = Estimated Total Intracranial Volume\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'eTIV',fill= True)\n",
        "facet.set(xlim=(0, df['eTIV'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(900, 2100)\n",
        "\n",
        "#'nWBV' = Normalized Whole Brain Volume\n",
        "# Nondemented = 0, Demented =1\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'nWBV',fill= True)\n",
        "facet.set(xlim=(0, df['nWBV'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(0.6,0.9)"
      ],
      "metadata": {
        "id": "JPuWkiWGslSS",
        "_uuid": "4dc483b489417595af5d23cf7a44de13c8ba371d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart indicates that Nondemented group has higher brain volume ratio than Demented group. This is assumed to be because the diseases affect the brain to be shrinking its tissue."
      ],
      "metadata": {
        "id": "1LC-PdJislSV",
        "_uuid": "96f2d269e35927b57c5068b2b3dda2d145ae91f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#AGE. Nondemented =0, Demented =1\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'Age',fill= True)\n",
        "facet.set(xlim=(0, df['Age'].max()))\n",
        "facet.add_legend()\n",
        "plt.xlim(50,100)"
      ],
      "metadata": {
        "id": "w6rN7jjSslSW",
        "_uuid": "87a846e38f21e28b3c7ad6bae536b7cd2c3e2466"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a higher concentration of 70-80 years old in the Demented patient group than those in the nondemented patients.\n",
        "We guess patients who suffered from that kind of disease has lower survival rate so that there are a few of 90 years old."
      ],
      "metadata": {
        "id": "VlQHpQRWslSY",
        "_uuid": "e491fe3ded880c040a17cde07279b0474b00ff7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'EDUC' = Years of Education\n",
        "# Nondemented = 0, Demented =1\n",
        "facet= sns.FacetGrid(df,hue=\"Group\", aspect=3)\n",
        "facet.map(sns.kdeplot,'EDUC',fill= True)\n",
        "facet.set(xlim=(df['EDUC'].min(), df['EDUC'].max()))\n",
        "facet.add_legend()\n",
        "plt.ylim(0, 0.16)"
      ],
      "metadata": {
        "_uuid": "8177a32eff0fece26f2220ccc046843347afc41e",
        "id": "TEGon6m3B3_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intermediate Result Summary\n",
        "1. Men are more likely with demented, an Alzheimer's Disease, than Women.\n",
        "2. Demented patients were less educated in terms of years of education.\n",
        "3. Nondemented group has higher brain volume than Demented group.\n",
        "4. Higher concentration of 70-80 years old in Demented group than those in the nondemented patients."
      ],
      "metadata": {
        "id": "HGKJOeWYslSZ",
        "_uuid": "26e6c99d943c7e371e9fd7c3b962449996e743fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fix data\n",
        "\n",
        "We identified 8 rows with missing values in SES column. We deal with this issue with 2 approaches. One is just to drop the rows with missing values. The other is to replace the missing values with the corresponing values, also known as 'Imputation'. Since we have only 150 data, I assume imputation would help the performance of our model."
      ],
      "metadata": {
        "id": "dR7e2FEuScR8",
        "_uuid": "80a9f0ebb50abd31cfa14ed7d93204d00f313543"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing values by each column\n",
        "pd.isnull(df).sum()\n",
        "# The column, SES has 8 missing values"
      ],
      "metadata": {
        "id": "crn5DxTUScSI",
        "_uuid": "c485e9bdba313a2897fa58aa61406f07c2206c27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing rows with missing values"
      ],
      "metadata": {
        "id": "v96VUyPYScSL",
        "_uuid": "10bb2143731149217bd59b8ea7fb2f12706dd355"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropped the 8 rows with missing values in the column, SES\n",
        "df_dropna = df.dropna(axis=0, how='any')\n",
        "pd.isnull(df_dropna).sum()"
      ],
      "metadata": {
        "id": "NCuXVrJtScSM",
        "_uuid": "71f15a1cda750ae72a718d2ec0aa7939ac2b7855"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropna['Group'].value_counts()"
      ],
      "metadata": {
        "id": "ThXMkCk0ScSQ",
        "_uuid": "a08f0ff032efa883e45e9b5bd2b6d386dd89f9b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw scatter plot between EDUC and SES\n",
        "x = df['EDUC']\n",
        "y = df['SES']\n",
        "\n",
        "ses_not_null_index = y[~y.isnull()].index\n",
        "x = x[ses_not_null_index]\n",
        "y = y[ses_not_null_index]\n",
        "\n",
        "# Draw trend line in red\n",
        "z = np.polyfit(x, y, 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(x, y, 'go', x, p(x), \"r--\")\n",
        "plt.xlabel('Education Level(EDUC)')\n",
        "plt.ylabel('Social Economic Status(SES)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "62IgZtwnScSV",
        "_uuid": "1c2354281b56aaac81b5dd09cee531be85a72b1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['EDUC'])['SES'].median()"
      ],
      "metadata": {
        "id": "cKaMRSvgScSY",
        "_uuid": "d2fcc229a25ba9ad1097de001cd53505ad0ba478"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"SES\"].fillna(df.groupby(\"EDUC\")[\"SES\"].transform(\"median\"), inplace=True)"
      ],
      "metadata": {
        "id": "dj_edAcdScSb",
        "_uuid": "b41fdf3fc1f569f482e8a506f0737775e84b338a",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There're no more missing values and all the 150 data were used.\n",
        "pd.isnull(df['SES']).value_counts()"
      ],
      "metadata": {
        "id": "Y4SgUM58ScSd",
        "_uuid": "63c36b7bc32f5cc65c8bf908113ba919a17fc5b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Train/Validation/Test Sets"
      ],
      "metadata": {
        "_uuid": "61220f51b25e5efcc5ceaa0d8f133967514b33a5",
        "id": "nD2XwGmMB3_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "kJcRjpOIScSj",
        "_uuid": "b039c111537091add5e04716b4d33501855155e8",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "Y = df['Group'].values # Target for the model\n",
        "X = df[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n",
        "\n",
        "# splitting into three sets\n",
        "X_trainval, X_test, Y_trainval, Y_test = train_test_split(\n",
        "    X, Y, random_state=0)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = MinMaxScaler().fit(X_trainval)\n",
        "X_trainval_scaled = scaler.transform(X_trainval)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "eI6EXWT7ScSm",
        "_uuid": "9c0cd7fedabdd26e4dbd2e5ed19a79c9097511c8",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset after dropping missing value rows\n",
        "Y = df_dropna['Group'].values # Target for the model\n",
        "X = df_dropna[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use\n",
        "\n",
        "# splitting into three sets\n",
        "X_trainval_dna, X_test_dna, Y_trainval_dna, Y_test_dna = train_test_split(\n",
        "    X, Y, random_state=0)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = MinMaxScaler().fit(X_trainval_dna)\n",
        "X_trainval_scaled_dna = scaler.transform(X_trainval_dna)\n",
        "X_test_scaled_dna = scaler.transform(X_test_dna)"
      ],
      "metadata": {
        "id": "oQAwHijeScSq",
        "_uuid": "aa47c091672863c3ad5c785a65cf227977cb9c37",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models (Algorithms)\n",
        "For each model different training parameters are evaluated. At the end, the best parameters for each model are printed with the results obtained."
      ],
      "metadata": {
        "id": "vgYxX0OkScSj",
        "_uuid": "27d4266a859c95510a8355df6c98c741a4805224"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix function\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    labels = unique_labels(y_true)\n",
        "    columns = [f'Predicted {label}' for label in labels]\n",
        "    index = [f'Actual {label}' for label in labels]\n",
        "    table = pd.DataFrame(confusion_matrix(y_true, y_pred),\n",
        "                         columns=columns, index=index)\n",
        "    return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')"
      ],
      "metadata": {
        "id": "7zwKxkigAENU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 (Logistic Regression)"
      ],
      "metadata": {
        "id": "L0zOT1CAScSu",
        "_uuid": "52d9efbf3184f96ff3a0767e08d3d1e6f8ea1a73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc"
      ],
      "metadata": {
        "_uuid": "f8dcc6798d6f0aa777fff85c880a47ec78ad9e5c",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Vs9ZJ1l6B3_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = [] # list to store all performance metric"
      ],
      "metadata": {
        "id": "nvBhRVT_ScSu",
        "_uuid": "252a6294c3c8754c0e19660e5ad7c0af189fd8e5",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "best_score=0\n",
        "kfolds=5 # set the number of folds\n",
        "\n",
        "for c in [0.001, 0.1, 1, 10, 100]:\n",
        "    logRegModel = LogisticRegression(C=c, max_iter=1000)\n",
        "    # perform cross-validation\n",
        "    scores = cross_val_score(logRegModel, X_trainval, Y_trainval, cv=kfolds, scoring='accuracy') # Get recall for each parameter setting\n",
        "\n",
        "    # compute mean cross-validation accuracy\n",
        "    score = np.mean(scores)\n",
        "\n",
        "    # Find the best parameters and score\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_parameters = c\n",
        "\n",
        "# rebuild a model on the combined training and validation set\n",
        "SelectedLogRegModel = LogisticRegression(C=best_parameters, max_iter=1000).fit(X_trainval_scaled, Y_trainval)\n",
        "\n",
        "test_score = SelectedLogRegModel.score(X_test_scaled, Y_test)\n",
        "PredictedOutput = SelectedLogRegModel.predict(X_test_scaled)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameter for regularization (C) is: \", best_parameters)\n",
        "print(\"Test accuracy with best C parameter is\", test_score)\n",
        "print(\"Test recall with the best C parameter is\", test_recall)\n",
        "print(\"Test AUC with the best C parameter is\", test_auc)\n",
        "m = 'Logistic Regression'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"
      ],
      "metadata": {
        "id": "xsWC0JpIScSw",
        "_uuid": "cb9f7249fa6793ec6e339aeb9936c26fbdfe552d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(Y_test, PredictedOutput)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y43zMcoFANFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 (SVM)"
      ],
      "metadata": {
        "id": "Gj3b-ssXScS2",
        "_uuid": "c3fcf0473df26fdea9ba51953aab1f53b2e522c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "\n",
        "for c_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter C\n",
        "    for gamma_paramter in [0.001, 0.01, 0.1, 1, 10, 100, 1000]: #iterate over the values we need to try for the parameter gamma\n",
        "        for k_parameter in ['rbf', 'linear', 'poly', 'sigmoid']: # iterate over the values we need to try for the kernel parameter\n",
        "            svmModel = SVC(kernel=k_parameter, C=c_paramter, gamma=gamma_paramter) #define the model\n",
        "            # perform cross-validation\n",
        "            scores = cross_val_score(svmModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n",
        "            # the training set will be split internally into training and cross validation\n",
        "\n",
        "            # compute mean cross-validation accuracy\n",
        "            score = np.mean(scores)\n",
        "            # if we got a better score, store the score and parameters\n",
        "            if score > best_score:\n",
        "                best_score = score #store the score\n",
        "                best_parameter_c = c_paramter #store the parameter c\n",
        "                best_parameter_gamma = gamma_paramter #store the parameter gamma\n",
        "                best_parameter_k = k_parameter\n",
        "\n",
        "\n",
        "# rebuild a model with best parameters to get score\n",
        "SelectedSVMmodel = SVC(C=best_parameter_c, gamma=best_parameter_gamma, kernel=best_parameter_k).fit(X_trainval_scaled, Y_trainval)\n",
        "\n",
        "test_score = SelectedSVMmodel.score(X_test_scaled, Y_test)\n",
        "PredictedOutput = SelectedSVMmodel.predict(X_test_scaled)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on cross validation set is:\", best_score)\n",
        "print(\"Best parameter for c is: \", best_parameter_c)\n",
        "print(\"Best parameter for gamma is: \", best_parameter_gamma)\n",
        "print(\"Best parameter for kernel is: \", best_parameter_k)\n",
        "print(\"Test accuracy with the best parameters is\", test_score)\n",
        "print(\"Test recall with the best parameters is\", test_recall)\n",
        "print(\"Test recall with the best parameter is\", test_auc)\n",
        "\n",
        "m = 'SVM'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"
      ],
      "metadata": {
        "id": "Xp5EM__NScS2",
        "_uuid": "527bf4c3aaeb65eeb16f929c2c8c82ce4c2263c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(Y_test, PredictedOutput)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FXNZqlCCAZxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 (Decision Tree)"
      ],
      "metadata": {
        "id": "mYGAer5hScS5",
        "_uuid": "2a111665a3aeefa0449d6e9b86efb45e14e5996d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "\n",
        "for md in range(1, 9): # iterate different maximum depth values\n",
        "    # train the model\n",
        "    treeModel = DecisionTreeClassifier(random_state=0, max_depth=md, criterion='gini')\n",
        "    # perform cross-validation\n",
        "    scores = cross_val_score(treeModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n",
        "\n",
        "    # compute mean cross-validation accuracy\n",
        "    score = np.mean(scores)\n",
        "\n",
        "    # if we got a better score, store the score and parameters\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_parameter = md\n",
        "\n",
        "# Rebuild a model on the combined training and validation set\n",
        "SelectedDTModel = DecisionTreeClassifier(max_depth=best_parameter).fit(X_trainval_scaled, Y_trainval )\n",
        "\n",
        "test_score = SelectedDTModel.score(X_test_scaled, Y_test)\n",
        "PredictedOutput = SelectedDTModel.predict(X_test_scaled)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameter for the maximum depth is: \", best_parameter)\n",
        "print(\"Test accuracy with best parameter is \", test_score)\n",
        "print(\"Test recall with best parameters is \", test_recall)\n",
        "print(\"Test AUC with the best parameter is \", test_auc)\n",
        "\n",
        "m = 'Decision Tree'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"
      ],
      "metadata": {
        "id": "jGI1Smg7ScS6",
        "_uuid": "4c27de17e77f9b986e27d2090113bce38bd67fba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(Y_test, PredictedOutput)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8xCCiV3JAc2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 4 (Random Forest Classifier)"
      ],
      "metadata": {
        "id": "ZkIF7600ScTD",
        "_uuid": "20608c740de79f3ea76598be6c3e3e8fd158fd82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "\n",
        "for M in range(2, 15, 2): # combines M trees\n",
        "    for d in range(1, 9): # maximum number of features considered at each split\n",
        "        for m in range(1, 9): # maximum depth of the tree\n",
        "            # train the model\n",
        "            # n_jobs(4) is the number of parallel computing\n",
        "            forestModel = RandomForestClassifier(n_estimators=M, max_features=d, n_jobs=4,\n",
        "                                          max_depth=m, random_state=0)\n",
        "\n",
        "            # perform cross-validation\n",
        "            scores = cross_val_score(forestModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n",
        "\n",
        "            # compute mean cross-validation accuracy\n",
        "            score = np.mean(scores)\n",
        "\n",
        "            # if we got a better score, store the score and parameters\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_M = M\n",
        "                best_d = d\n",
        "                best_m = m\n",
        "\n",
        "# Rebuild a model on the combined training and validation set\n",
        "SelectedRFModel = RandomForestClassifier(n_estimators=M, max_features=d,\n",
        "                                          max_depth=m, random_state=0).fit(X_trainval_scaled, Y_trainval )\n",
        "\n",
        "PredictedOutput = SelectedRFModel.predict(X_test_scaled)\n",
        "test_score = SelectedRFModel.score(X_test_scaled, Y_test)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameters of M, d, m are: \", best_M, best_d, best_m)\n",
        "print(\"Test accuracy with the best parameters is\", test_score)\n",
        "print(\"Test recall with the best parameters is:\", test_recall)\n",
        "print(\"Test AUC with the best parameters is:\", test_auc)\n",
        "\n",
        "m = 'Random Forest'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"
      ],
      "metadata": {
        "id": "zi0Ssns3ScTE",
        "_uuid": "0314f070def4da297b2b8712cea7727f6d5d8112"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(Y_test, PredictedOutput)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hx-V9gl1Ad2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 5 (AdaBoost)"
      ],
      "metadata": {
        "_uuid": "ea3b9dd38fd2bbfe32e1cdd35ed6a3cdfa2dbccc",
        "id": "cR6-hf4cB3_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_score = 0\n",
        "\n",
        "for M in range(2, 15, 2): # combines M trees\n",
        "    for lr in [0.0001, 0.001, 0.01, 0.1, 1]:\n",
        "        # train the model\n",
        "        boostModel = AdaBoostClassifier(n_estimators=M, learning_rate=lr, random_state=0)\n",
        "\n",
        "        # perform cross-validation\n",
        "        scores = cross_val_score(boostModel, X_trainval_scaled, Y_trainval, cv=kfolds, scoring='accuracy')\n",
        "\n",
        "        # compute mean cross-validation accuracy\n",
        "        score = np.mean(scores)\n",
        "\n",
        "        # if we got a better score, store the score and parameters\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_M = M\n",
        "            best_lr = lr\n",
        "\n",
        "# Rebuild a model on the combined training and validation set\n",
        "SelectedBoostModel = AdaBoostClassifier(n_estimators=M, learning_rate=lr, random_state=0).fit(X_trainval_scaled, Y_trainval )\n",
        "\n",
        "PredictedOutput = SelectedBoostModel.predict(X_test_scaled)\n",
        "test_score = SelectedRFModel.score(X_test_scaled, Y_test)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameter of M is: \", best_M)\n",
        "print(\"best parameter of LR is: \", best_lr)\n",
        "print(\"Test accuracy with the best parameter is\", test_score)\n",
        "print(\"Test recall with the best parameters is:\", test_recall)\n",
        "print(\"Test AUC with the best parameters is:\", test_auc)\n",
        "\n",
        "m = 'AdaBoost'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"
      ],
      "metadata": {
        "_uuid": "9eab03ab2cd59e507dc30b632c60fb0aeb1d2c37",
        "id": "wm3M2ehJB3_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(Y_test, PredictedOutput)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OLWVGt8wAehJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "w1vFrwcwScTO",
        "_uuid": "5defe4c299e6a47547b1d05a533c90aba26c0365"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance Metric for each model\n",
        "result = pd.DataFrame(acc, columns=['Model', 'Accuracy', 'Recall', 'AUC', 'FPR', 'TPR', 'TH'])\n",
        "result[['Model', 'Accuracy', 'Recall', 'AUC']]"
      ],
      "metadata": {
        "_uuid": "567d27a76de89fd5c9feb715bfc0e58400872f7e",
        "id": "LcrsZFxnB3_i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
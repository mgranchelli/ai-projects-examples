{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2260133,
          "sourceType": "datasetVersion",
          "datasetId": 1360225
        }
      ],
      "dockerImageVersionId": 30120,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgranchelli/ai-projects-examples/blob/main/RunningInjuryPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnyBRJ0z1Fr7"
      },
      "source": [
        "# Injury prediction for Competitive Runners"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uogoJLxD1Fr9"
      },
      "source": [
        "**ContextüèÉ**\n",
        "\n",
        "Running is a great form of exercise, recreation, and sport participation for adults, adolescents, and children. Whether alone or in a team environment, running, when done properly, can enhance physical fitness, coordination, sense of accomplishment, and physical and emotional development. However, running under adverse conditions or with inadequate clothing and equipment can cause a variety of injuries and physical stress.\n",
        "\n",
        "**ContentüèÉ**\n",
        "\n",
        "The data set consists of a detailed training log from a Dutch high-level running team over a period of seven years (2012-2019). We included the middle and long-distance runners of the team, that is, those competing on distances between the 800 meters and the marathon. This design decision is motivated by the fact that these groups have strong endurance-based components in their training, making their training regimes comparable. The head coach of the team did not change during the years of data collection.\n",
        "\n",
        "The data set contains samples from 74 runners, of whom 27 are women and 47 are men. At the moment of data collection, they had been in the team for an average of 3.7 years. Most athletes competed on a national level, and some also on an international level. The study was conducted according to the requirements of the Declaration of Helsinki and was approved by the ethics committee of the second author‚Äôs institution\n",
        "\n",
        "**AcknowledgementsüèÉ**\n",
        "\n",
        "S. Lovdal, Ruud J. R. Den Hartigh, G. Azzopardi, \"Injury Prediction in Competitive Runners with Machine Learning\", International Journal of Sports Physiology and Performance, 2020, in press."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data"
      ],
      "metadata": {
        "id": "3-gJj11NNnrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown -q"
      ],
      "metadata": {
        "id": "u16J38Z1Nsd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=10bur-F5sEANpKvKiIwi_exK2DCMe2fRh"
      ],
      "metadata": {
        "id": "bdT-UsI5Nvve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q injury.zip"
      ],
      "metadata": {
        "id": "Ep-NJUdCNyOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import modules"
      ],
      "metadata": {
        "id": "0HdgD6cnRq7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn import datasets, metrics"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:40.841222Z",
          "iopub.execute_input": "2023-02-12T03:27:40.841613Z",
          "iopub.status.idle": "2023-02-12T03:27:40.854511Z",
          "shell.execute_reply.started": "2023-02-12T03:27:40.841583Z",
          "shell.execute_reply": "2023-02-12T03:27:40.853265Z"
        },
        "trusted": true,
        "id": "0STwTf-b2weW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                            Introduction\n",
        "Running is one of the most popular sports in the world. [60 million](http://https://www.statista.com/topics/1743/running-and-jogging/#topicHeader__wrapper) people participated in jogging, running, or trail running in America alone in 2017. But it is reported that [50%](https://www.yalemedicine.org/conditions/running-injury#:~:text=In%20fact%2C%20at%20least%2050,People%20who%20run%2C%20love%20it.) of runners get injured every year. Dealing with injuries can be a hard and long process, which is why runners take many precautions to mitigate the chance of injuries. These precautions include investments in rollers, massages, and professional coaching to name a few. But these resources take investments that many people can not afford. With the advances in data science, many people are wondering wether machine learning will be able to reduce the barrier for injury prediction resources. In our analysis we will see how popular machine learning algorithms deal with predciting injuries using running data"
      ],
      "metadata": {
        "id": "_ecuofwA2wea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "9gJPI9Bl3KAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"injury/week_approach_maskedID_timeseries.csv\")\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:40.856443Z",
          "iopub.execute_input": "2023-02-12T03:27:40.857056Z",
          "iopub.status.idle": "2023-02-12T03:27:41.177893Z",
          "shell.execute_reply.started": "2023-02-12T03:27:40.856986Z",
          "shell.execute_reply": "2023-02-12T03:27:41.177014Z"
        },
        "trusted": true,
        "id": "PdrDUIlq2wea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will do some basic data exploration to understand if the data set is dirty."
      ],
      "metadata": {
        "id": "y4IaKGIz2wec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_Values = df.isnull().sum()\n",
        "missing_Values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:41.179487Z",
          "iopub.execute_input": "2023-02-12T03:27:41.179943Z",
          "iopub.status.idle": "2023-02-12T03:27:41.195039Z",
          "shell.execute_reply.started": "2023-02-12T03:27:41.179911Z",
          "shell.execute_reply": "2023-02-12T03:27:41.193909Z"
        },
        "trusted": true,
        "id": "qaO1ke3H2wed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:41.197139Z",
          "iopub.execute_input": "2023-02-12T03:27:41.197916Z",
          "iopub.status.idle": "2023-02-12T03:27:41.454515Z",
          "shell.execute_reply.started": "2023-02-12T03:27:41.197861Z",
          "shell.execute_reply": "2023-02-12T03:27:41.453462Z"
        },
        "trusted": true,
        "id": "0nnBirY92wee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:41.45607Z",
          "iopub.execute_input": "2023-02-12T03:27:41.456695Z",
          "iopub.status.idle": "2023-02-12T03:27:41.498411Z",
          "shell.execute_reply.started": "2023-02-12T03:27:41.456645Z",
          "shell.execute_reply": "2023-02-12T03:27:41.497254Z"
        },
        "trusted": true,
        "id": "i1MNa6Yl2wef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove data"
      ],
      "metadata": {
        "id": "QoJs7Br_3SwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The data is too high dimension for us to start data analysis. We will start off by dropping attributes based on empirical analysis. Any attributes based on how the person feels was removed from the data set. We wanted to do see if we could predict data strictly based on the quality of running using quantative data. Although 'recovery' attributes could be useful, its very hard to accurately understand how a runners body is feeling based off of survey questions."
      ],
      "metadata": {
        "id": "UmHLnz3x2weg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df = df.drop(['avg training success', 'min training success', 'max training success', 'avg training success.1', 'max training success.1', 'min training success.1'], axis = 1)\n",
        "df = df.drop(['avg training success.2', 'max training success.2', 'min training success.2', 'avg exertion', 'min exertion', 'max exertion'], axis = 1)\n",
        "df = df.drop(['avg exertion.1', 'min exertion.1', 'max exertion.1', 'avg exertion.2', 'min exertion.2', 'max exertion.2', 'max km one day'], axis = 1)\n",
        "df = df.drop(['avg recovery', 'min recovery', 'max recovery', 'avg recovery.1', 'min recovery.1', 'max recovery.1', 'avg recovery.2', 'min recovery.2', 'max recovery.2'], axis = 1)\n",
        "df = df.drop(['rel total kms week 0_1', 'rel total kms week 0_2', 'rel total kms week 1_2'], axis = 1)\n",
        "df.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:41.499941Z",
          "iopub.execute_input": "2023-02-12T03:27:41.500434Z",
          "iopub.status.idle": "2023-02-12T03:27:41.572629Z",
          "shell.execute_reply.started": "2023-02-12T03:27:41.50039Z",
          "shell.execute_reply": "2023-02-12T03:27:41.571781Z"
        },
        "trusted": true,
        "id": "UMjuYzQz2weg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have succesfully reduced the attributes of the data set from 71 to 40. This is a good start but the data set is still to high dimensional."
      ],
      "metadata": {
        "id": "FKfv2h6D2weh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration"
      ],
      "metadata": {
        "id": "GS1vHkoD4YJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Athlete ID'].unique()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:41.573874Z",
          "iopub.execute_input": "2023-02-12T03:27:41.574182Z",
          "iopub.status.idle": "2023-02-12T03:27:41.581583Z",
          "shell.execute_reply.started": "2023-02-12T03:27:41.574152Z",
          "shell.execute_reply": "2023-02-12T03:27:41.580097Z"
        },
        "trusted": true,
        "id": "7bhKIZOH2weh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In total there are 74 athletes. Let's isolate the first athlete and see what their training looks like.\n"
      ],
      "metadata": {
        "id": "2SAfr60G2wei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexIndividualData(id):\n",
        "  df0 = df[df['Athlete ID'] == id]\n",
        "  index1 = df0.index[0]\n",
        "  indexLast = df0.index[-1]\n",
        "  y = indexLast - len(df0[df0['injury']==0]) - len(df0[df0['injury']==1])\n",
        "  df0 = df0.rename(index = lambda x: x - y - 1 if x > indexLast - len(df0[df0['injury']==1]) else x - index1)\n",
        "  df0 = df0.sort_values(by = 'Date')\n",
        "  return df0\n",
        "def plotIndividualData(id, column):\n",
        "  df0 = indexIndividualData(id)\n",
        "  plt.figure(figsize = (14,6))\n",
        "  sns.lineplot(data=df0[column])\n",
        "\n",
        "plotIndividualData(1, \"total kms\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:41.582885Z",
          "iopub.execute_input": "2023-02-12T03:27:41.583185Z",
          "iopub.status.idle": "2023-02-12T03:27:42.056015Z",
          "shell.execute_reply.started": "2023-02-12T03:27:41.583156Z",
          "shell.execute_reply": "2023-02-12T03:27:42.054903Z"
        },
        "trusted": true,
        "id": "jUclx4JS2wej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph does lead us to some questions. Why is there a drop in training for such a long period for this athlete? Assuming each data point is a week, over one hundred weeks of being injured does not make sense. It could make more sense if the points are actually days, but one hundred days injured is also a lot."
      ],
      "metadata": {
        "id": "E3W9ViuS2wek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dateInjurySubset(id, column1, column2, column3):\n",
        "  df0 = indexIndividualData(id)\n",
        "  return df0[[column1,column2,column3]]\n",
        "\n",
        "def plotIndividualDataDuoColumn(id, column1, column2, column3):\n",
        "  df0 = dateInjurySubset(id,column1,column2,column3)\n",
        "  plt.figure(figsize = (14,6))\n",
        "  sns.lineplot(data=df0)\n",
        "\n",
        "print(dateInjurySubset(1,\"total kms\", \"total kms.1\",\"total kms.2\").mean())\n",
        "plotIndividualDataDuoColumn(1,\"total kms\", \"total kms.1\", \"total kms.2\")\n",
        "print(dateInjurySubset(1,\"nr. sessions\", \"nr. sessions.1\",\"nr. sessions.2\").mean())\n",
        "plotIndividualDataDuoColumn(1,\"nr. sessions\", \"nr. sessions.1\",\"nr. sessions.2\")\n",
        "print(dateInjurySubset(2,\"total kms\", \"total kms.1\",\"total kms.2\").mean())\n",
        "plotIndividualDataDuoColumn(2,\"total kms\", \"total kms.1\", \"total kms.2\")\n",
        "print(dateInjurySubset(2,\"nr. sessions\", \"nr. sessions.1\",\"nr. sessions.2\").mean())\n",
        "plotIndividualDataDuoColumn(2,\"nr. sessions\", \"nr. sessions.1\",\"nr. sessions.2\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:42.058743Z",
          "iopub.execute_input": "2023-02-12T03:27:42.05923Z",
          "iopub.status.idle": "2023-02-12T03:27:47.804701Z",
          "shell.execute_reply.started": "2023-02-12T03:27:42.059172Z",
          "shell.execute_reply": "2023-02-12T03:27:47.803561Z"
        },
        "trusted": true,
        "id": "EvCaSXx82wel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there does not seem to be any difference between the attributes and their \".1\",\".2\" siblings, the attributes seem to be just noise. It could be justification to drop all the suffix attributes, as we are not sure what they contribute to the data"
      ],
      "metadata": {
        "id": "5qFskIGV2wem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfQ2 = df[['Athlete ID', 'total km Z3-Z4-Z5-T1-T2', 'total km Z3-Z4-Z5-T1-T2.1', 'total km Z3-Z4-Z5-T1-T2.2', 'injury', 'nr. tough sessions (effort in Z5, T1 or T2)', 'nr. tough sessions (effort in Z5, T1 or T2).1', 'nr. tough sessions (effort in Z5, T1 or T2).2', 'total km Z5-T1-T2', 'total km Z5-T1-T2.1', 'total km Z5-T1-T2.2', 'total km Z3-4', 'total km Z3-4.1', 'total km Z3-4.2']]\n",
        "dfArray = []\n",
        "for i in df['Athlete ID'].unique():\n",
        "  dfArray.append(indexIndividualData(i))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:27:47.806647Z",
          "iopub.execute_input": "2023-02-12T03:27:47.80708Z",
          "iopub.status.idle": "2023-02-12T03:28:10.094765Z",
          "shell.execute_reply.started": "2023-02-12T03:27:47.807034Z",
          "shell.execute_reply": "2023-02-12T03:28:10.093912Z"
        },
        "trusted": true,
        "id": "bTuHzWWk2wem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'dates' attribute is also confusing in this data set. We will try and visualize it to get a better idea of what it means."
      ],
      "metadata": {
        "id": "Q-koDxs_2wem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = dfArray[1]\n",
        "injury = df0[df0['injury'] == 1]\n",
        "notInjured = df0[df0['injury'] == 0]\n",
        "print(\"INJURED DATES ID 1\")\n",
        "for i in injury['Date']:\n",
        "  print(i)\n",
        "print(\"NOT INJURED DATES ID 1:\\n\")\n",
        "for i in notInjured['Date']:\n",
        "  print(i)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:10.096051Z",
          "iopub.execute_input": "2023-02-12T03:28:10.096534Z",
          "iopub.status.idle": "2023-02-12T03:28:10.177938Z",
          "shell.execute_reply.started": "2023-02-12T03:28:10.096476Z",
          "shell.execute_reply": "2023-02-12T03:28:10.17541Z"
        },
        "trusted": true,
        "id": "Bu8w_9Fo2wen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why the 'dates' attribute jumps from 400 to 700 for an athlete does not make sense to us. In order to accurately predict date there should be consecutive date that can be analyzed. We could be missing something but we cant attemt to try and classify the running data anyways. The data exploration also showed us that the data set is extremely biased towards the non-injured data."
      ],
      "metadata": {
        "id": "VH0ji6pi2weo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "sns.countplot(x='injury', data=df0)\n",
        "plt.title('Unbalanced Classes')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:10.180004Z",
          "iopub.execute_input": "2023-02-12T03:28:10.180421Z",
          "iopub.status.idle": "2023-02-12T03:28:10.301986Z",
          "shell.execute_reply.started": "2023-02-12T03:28:10.180383Z",
          "shell.execute_reply": "2023-02-12T03:28:10.300936Z"
        },
        "trusted": true,
        "id": "uYwjVXDJ2wep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see just how biased the data set is for non-injured cases."
      ],
      "metadata": {
        "id": "abrZO3W52wep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balancing dataset"
      ],
      "metadata": {
        "id": "GQRlPaHu5xlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df0.sort_values(by = 'Athlete ID');\n",
        "\n",
        "shuffled_df1 = df.sample(frac=1,random_state=4)\n",
        "\n",
        "# Put all the fraud class in a separate dataset.\n",
        "injury_df1 = shuffled_df1.loc[shuffled_df1['injury'] == 1]\n",
        "\n",
        "#Randomly select 492 observations from the non-fraud (majority class)\n",
        "non_injured_df1 = shuffled_df1.loc[shuffled_df1['injury'] == 0].sample(n=575)\n",
        "\n",
        "# Concatenate both dataframes again\n",
        "normalized_df = pd.concat([injury_df1, non_injured_df1])\n",
        "\n",
        "#plot the dataset after the undersampling\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.countplot(x='injury', data=normalized_df)\n",
        "plt.title('Balanced Classes')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:10.303121Z",
          "iopub.execute_input": "2023-02-12T03:28:10.303407Z",
          "iopub.status.idle": "2023-02-12T03:28:10.459198Z",
          "shell.execute_reply.started": "2023-02-12T03:28:10.303378Z",
          "shell.execute_reply": "2023-02-12T03:28:10.458115Z"
        },
        "trusted": true,
        "id": "23ipUTxg2weq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we balance out the data set using sampling. This should allow us to avoid overffiting in our predictive models."
      ],
      "metadata": {
        "id": "hsgdcTNB2weq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will start of by showing what happens when the data set is skewed. You will see that the accruacy is very high for the unbalanced data set because the classifier will identify all the data points as non-injured. This would be uselss for the goal of this project."
      ],
      "metadata": {
        "id": "XuYYTfYk2weq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df0['injury']\n",
        "X = df0.drop('injury', axis=1)\n",
        "X = df0.drop('Athlete ID', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "             X, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "K = []\n",
        "training = []\n",
        "test = []\n",
        "scores = {}\n",
        "\n",
        "for k in range(2, 21):\n",
        "    clf = KNeighborsClassifier(n_neighbors = k)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    training_score = clf.score(X_train, y_train)\n",
        "    test_score = clf.score(X_test, y_test)\n",
        "    K.append(k)\n",
        "\n",
        "    training.append(training_score)\n",
        "    test.append(test_score)\n",
        "    scores[k] = [training_score, test_score]\n",
        "\n",
        "for keys, values in scores.items():\n",
        "    print(keys, ':', values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:10.460577Z",
          "iopub.execute_input": "2023-02-12T03:28:10.460911Z",
          "iopub.status.idle": "2023-02-12T03:28:11.003768Z",
          "shell.execute_reply.started": "2023-02-12T03:28:10.460874Z",
          "shell.execute_reply": "2023-02-12T03:28:11.002583Z"
        },
        "trusted": true,
        "id": "KYSk5bl32weq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "def plot_confusion_matrix(y_true, y_pred):\n",
        "    labels = unique_labels(y_true)\n",
        "    columns = [f'Predicted {label}' for label in labels]\n",
        "    index = [f'Actual {label}' for label in labels]\n",
        "    table = pd.DataFrame(confusion_matrix(y_true, y_pred),\n",
        "                         columns=columns, index=index)\n",
        "    return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')"
      ],
      "metadata": {
        "id": "t8ctsNr16bEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "plot_confusion_matrix(y_test, y_pred)\n",
        "svc_disp = RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d8S0lJ287E6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix above shows that all data points are identified as non-injured. We will try and use the balanced data set next."
      ],
      "metadata": {
        "id": "tIE69OxO2wer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = normalized_df['injury']\n",
        "X = normalized_df.drop('injury', axis=1)\n",
        "X = normalized_df.drop('Athlete ID', axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "             X, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "K = []\n",
        "training = []\n",
        "test = []\n",
        "scores = {}\n",
        "\n",
        "for k in range(2, 21):\n",
        "    clf = KNeighborsClassifier(n_neighbors = k)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    training_score = clf.score(X_train, y_train)\n",
        "    test_score = clf.score(X_test, y_test)\n",
        "    K.append(k)\n",
        "\n",
        "    training.append(training_score)\n",
        "    test.append(test_score)\n",
        "    scores[k] = [training_score, test_score]\n",
        "\n",
        "for keys, values in scores.items():\n",
        "    print(keys, ':', values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:11.342695Z",
          "iopub.execute_input": "2023-02-12T03:28:11.343149Z",
          "iopub.status.idle": "2023-02-12T03:28:12.459459Z",
          "shell.execute_reply.started": "2023-02-12T03:28:11.343101Z",
          "shell.execute_reply": "2023-02-12T03:28:12.458224Z"
        },
        "trusted": true,
        "id": "pTYRXQoT2wes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that as we increase the paramater k, the training accuracy goes down significantly (from about 80% to 65%) and the testing accuracy increases slighlty (from about 58% to 60%). We will use the confusion matrix to see how well the predictive model is handling the non-injured data compared to the injured data."
      ],
      "metadata": {
        "id": "RuaYRGpI2wes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " clf = KNeighborsClassifier(n_neighbors = 2)\n",
        " clf.fit(X_train, y_train)\n",
        "\n",
        " training_score = clf.score(X_train, y_train)\n",
        " test_score = clf.score(X_test, y_test)\n",
        " K.append(k)\n",
        "\n",
        " training.append(training_score)\n",
        " test.append(test_score)\n",
        " scores[k] = [training_score, test_score]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:12.460912Z",
          "iopub.execute_input": "2023-02-12T03:28:12.461273Z",
          "iopub.status.idle": "2023-02-12T03:28:12.526805Z",
          "shell.execute_reply.started": "2023-02-12T03:28:12.461238Z",
          "shell.execute_reply": "2023-02-12T03:28:12.525583Z"
        },
        "trusted": true,
        "id": "Nio_T7Lp2wet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "plot_confusion_matrix(y_test, y_pred)\n",
        "svc_disp = RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:12.528199Z",
          "iopub.execute_input": "2023-02-12T03:28:12.52853Z",
          "iopub.status.idle": "2023-02-12T03:28:12.866795Z",
          "shell.execute_reply.started": "2023-02-12T03:28:12.528494Z",
          "shell.execute_reply": "2023-02-12T03:28:12.865704Z"
        },
        "trusted": true,
        "id": "ndRgMvCd2wet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the k value of 2, the classifier seems to be more accurate at predicintg the non-injured data."
      ],
      "metadata": {
        "id": "s4KRmS7q2wet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " clf = KNeighborsClassifier(n_neighbors = 12)\n",
        " clf.fit(X_train, y_train)\n",
        "\n",
        " training_score = clf.score(X_train, y_train)\n",
        " test_score = clf.score(X_test, y_test)\n",
        " K.append(k)\n",
        "\n",
        " training.append(training_score)\n",
        " test.append(test_score)\n",
        " scores[k] = [training_score, test_score]\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "plot_confusion_matrix(y_test, y_pred)\n",
        "svc_disp = RocCurveDisplay.from_estimator(clf, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:12.867979Z",
          "iopub.execute_input": "2023-02-12T03:28:12.868289Z",
          "iopub.status.idle": "2023-02-12T03:28:13.269054Z",
          "shell.execute_reply.started": "2023-02-12T03:28:12.868259Z",
          "shell.execute_reply": "2023-02-12T03:28:13.267975Z"
        },
        "trusted": true,
        "id": "WTxXZ10g2weu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a high k value of 21, you get more acurate injury prediction, but that also means a lot more false positives for non-injure data, meaning the classifier identifies those people who are not injured as injured at a much higher rate.  "
      ],
      "metadata": {
        "id": "Ck3Tp2K92weu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The equilibrium that we found was a k parameter value of 12, with an overall accuracy rate of 60%, 52% for non-injured data points and 68% accuracy for predicting injured data points. This is decent considering how biased the data set is but there are other binary classifiers and other balancing method that we will test to see if we can get better accuracy."
      ],
      "metadata": {
        "id": "ZXXtlFPo2weu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM classifier using undersampling\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "X = df.drop('injury', axis = 1)\n",
        "Y = df['injury']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, stratify = Y)\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "X_train, Y_train =rus.fit_resample(X_train,Y_train)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "Y_pred = classifier.predict(X_test)\n",
        "plot_confusion_matrix(Y_test, Y_pred)\n",
        "svc_disp = RocCurveDisplay.from_estimator(classifier, X_test, Y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:52:47.204463Z",
          "iopub.execute_input": "2023-02-12T03:52:47.204826Z",
          "iopub.status.idle": "2023-02-12T03:52:48.237378Z",
          "shell.execute_reply.started": "2023-02-12T03:52:47.204796Z",
          "shell.execute_reply": "2023-02-12T03:52:48.236227Z"
        },
        "trusted": true,
        "id": "FFIak33K2wev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code involves using a support vector machine classifier to predict whether a data point is injured or not using the undersampling technique to counter our imbalanced data set."
      ],
      "metadata": {
        "id": "YI31yvK92wev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM Classifier using oversampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "X = df.drop('injury', axis = 1)\n",
        "Y = df['injury']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, stratify = Y)\n",
        "sm = SMOTE(random_state = 0)\n",
        "X_train, Y_train = sm.fit_resample(X_train,Y_train)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier.fit(X_train, Y_train)\n",
        "Y_pred = classifier.predict(X_test)\n",
        "plot_confusion_matrix(Y_test, Y_pred)\n",
        "svc_disp = RocCurveDisplay.from_estimator(classifier, X_test, Y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:52:59.656468Z",
          "iopub.execute_input": "2023-02-12T03:52:59.656836Z",
          "iopub.status.idle": "2023-02-12T03:56:49.591116Z",
          "shell.execute_reply.started": "2023-02-12T03:52:59.656805Z",
          "shell.execute_reply": "2023-02-12T03:56:49.589755Z"
        },
        "trusted": true,
        "id": "MveJbHne2wev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code involves using a support vector machine classifier to predict whether a data point is injured or not using the oversampling technique to counter our imbalanced data set."
      ],
      "metadata": {
        "id": "te3WvNbA2wew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagging Classifier With Undersampling\n",
        "import sklearn.ensemble\n",
        "X = df.drop('injury', axis = 1)\n",
        "Y = df['injury']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, stratify = Y)\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "X_train, Y_train =rus.fit_resample(X_train,Y_train)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "bag = sklearn.ensemble.BaggingClassifier(n_estimators = 35)\n",
        "bag.fit(X_train, Y_train)\n",
        "Y_pred = bag.predict(X_test)\n",
        "plot_confusion_matrix(Y_test, Y_pred)\n",
        "svc_disp = RocCurveDisplay.from_estimator(bag, X_test, Y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:14.174242Z",
          "iopub.status.idle": "2023-02-12T03:28:14.174639Z"
        },
        "trusted": true,
        "id": "ExReTJ5u2wew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code involves using a bagging classifier to predict whether a data point is injured or not using the undersampling technique to counter our imbalanced data set."
      ],
      "metadata": {
        "id": "MedywUeD2wex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagging Classifier With Oversampling\n",
        "import sklearn.ensemble\n",
        "X = df.drop('injury', axis = 1)\n",
        "Y = df['injury']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, stratify = Y)\n",
        "sm = SMOTE(random_state = 0)\n",
        "X_train, Y_train = sm.fit_resample(X_train,Y_train)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "bag = sklearn.ensemble.BaggingClassifier(n_estimators = 30)\n",
        "bag.fit(X_train, Y_train)\n",
        "Y_pred = bag.predict(X_test)\n",
        "plot_confusion_matrix(Y_test, Y_pred)\n",
        "svc_disp = RocCurveDisplay.from_estimator(bag, X_test, Y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:14.175641Z",
          "iopub.status.idle": "2023-02-12T03:28:14.176066Z"
        },
        "trusted": true,
        "id": "BqN8WXz82wex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code involves using a bagging classifier to predict whether a data point is injured or not using the oversampling technique to counter our imbalanced data set."
      ],
      "metadata": {
        "id": "reVDo3vJ2wex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBooster model with Undersampling\n",
        "from xgboost import XGBClassifier\n",
        "X = df.drop('injury', axis = 1)\n",
        "Y = df['injury']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, stratify = Y)\n",
        "rus = RandomUnderSampler(random_state=0)\n",
        "X_train, Y_train =rus.fit_resample(X_train,Y_train)\n",
        "boost = XGBClassifier(max_depth = 3, n_estimators = 30)\n",
        "boost.fit(X_train, Y_train)\n",
        "Y_pred = boost.predict(X_test)\n",
        "plot_confusion_matrix(Y_test, Y_pred)\n",
        "svc_disp = RocCurveDisplay.from_estimator(boost, X_test, Y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:14.176887Z",
          "iopub.status.idle": "2023-02-12T03:28:14.177307Z"
        },
        "trusted": true,
        "id": "LgDUWGBi2wey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code involves using the XGBooster classifier to predict whether a data point is injured or not using the undersampling technique to counter our imbalanced data set."
      ],
      "metadata": {
        "id": "Xzbs0Tff2wey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBooster model with Oversampling\n",
        "from xgboost import XGBClassifier\n",
        "X = df.drop('injury', axis = 1)\n",
        "Y = df['injury']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, stratify = Y)\n",
        "sm = SMOTE(random_state = 0)\n",
        "X_train, Y_train = sm.fit_resample(X_train,Y_train)\n",
        "boost = XGBClassifier(max_depth = 2, n_estimators = 30)\n",
        "boost.fit(X_train, Y_train)\n",
        "Y_pred = boost.predict(X_test)\n",
        "plot_confusion_matrix(Y_test, Y_pred)\n",
        "svc_disp = RocCurveDisplay.from_estimator(boost, X_test, Y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-02-12T03:28:14.178326Z",
          "iopub.status.idle": "2023-02-12T03:28:14.178731Z"
        },
        "trusted": true,
        "id": "4MNUQ2G-2wey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code involves using a bagging classifier to predict whether a data point is injured or not using the oversampling technique to counter our imbalanced data set."
      ],
      "metadata": {
        "id": "iZ-UbJdb2wez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the results of the models showed that the model accuracy was more dependent on whether oversampling or undersampling was used. The oversampling method was more successful at classifying data points that were actually non-injured, while the undersampling method did a much better job at accurately classifying the points that were actually injured."
      ],
      "metadata": {
        "id": "yNY-JK9p2wez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                      Conclusion\n",
        "We balanced the data set using multiple different strategies, such as sampling, oversampling, and undersampling. The different balanced datasets where tested on several different binary classifiers, such as KNN, SVM, Bagging, and XGBooster. The highest accruacy we achieved is with XGBooster and Bagging with a 99% accuracy rate. The downside for this accuracy is overfitting as the minority class has a 0% predicted accuracy. The classifier which has the best accuracy equilibrium in proportion to the minority and majority class is XGBooster with Undersampling. This had a 60% overall accuracy rate, with 60% for injured prediction and 60% for non-injured prediction. Neither of these predicted accuracies are useful. The high accuracy overfits, and the lower accuracy is not good enough for real life application."
      ],
      "metadata": {
        "id": "RmYwIQno2wez"
      }
    }
  ]
}
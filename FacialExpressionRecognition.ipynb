{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 127160,
          "sourceType": "datasetVersion",
          "datasetId": 64677
        }
      ],
      "dockerImageVersionId": 29869,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgranchelli/ai-projects-examples/blob/main/FacialExpressionRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Facial Expression\n",
        "\n"
      ],
      "metadata": {
        "id": "agcrDMbiNk8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download data"
      ],
      "metadata": {
        "id": "3-gJj11NNnrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown -q"
      ],
      "metadata": {
        "id": "u16J38Z1Nsd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=10oTFlIeiXbpVnyg58GiboTrDo7GT_VLH"
      ],
      "metadata": {
        "id": "bdT-UsI5Nvve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q facial-expression-data.zip"
      ],
      "metadata": {
        "id": "Ep-NJUdCNyOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import library"
      ],
      "metadata": {
        "id": "NZY1X2InOhOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "zyKUFb1cyTHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "z-09vrhRzyr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('fer2013.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "SE-1XgWbyTHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.emotion.unique()"
      ],
      "metadata": {
        "trusted": true,
        "id": "XSNj84AtyTHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_label_to_text = {0:'anger', 1:'disgust', 2:'fear', 3:'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}"
      ],
      "metadata": {
        "trusted": true,
        "id": "lDWA66dlyTHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.emotion.value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "j5TDMPVoyTHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df, x='emotion')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sRdDOihS2yYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So majority classes belongs to 3:Happy, 4:Sad and 6:Neutral and we are also intersted in these three classes only.\n",
        "\n"
      ],
      "metadata": {
        "id": "C8bPJqot4MQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image size\n",
        "math.sqrt(len(df.pixels[0].split(' ')))"
      ],
      "metadata": {
        "trusted": true,
        "id": "-9oKYolJyTHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show examples"
      ],
      "metadata": {
        "id": "2QM63GoT4hO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = pyplot.figure(1, (14, 14))\n",
        "\n",
        "k = 0\n",
        "for label in sorted(df.emotion.unique()):\n",
        "    for j in range(7):\n",
        "        px = df[df.emotion==label].pixels.iloc[k]\n",
        "        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n",
        "\n",
        "        k += 1\n",
        "        ax = pyplot.subplot(7, 7, k)\n",
        "        ax.imshow(px, cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_title(emotion_label_to_text[label])\n",
        "        pyplot.tight_layout()"
      ],
      "metadata": {
        "trusted": true,
        "id": "SAUDPTqLyTHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider only 3 classes:\n",
        "**3:Happy, 4:Sad and 6:Neutral**"
      ],
      "metadata": {
        "id": "nC6jEzMo4qL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INTERESTED_LABELS = [3, 4, 6]"
      ],
      "metadata": {
        "trusted": true,
        "id": "bN6-BtSlyTHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.emotion.isin(INTERESTED_LABELS)]\n",
        "df.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "C4DOMsV0yTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load image from pixels"
      ],
      "metadata": {
        "id": "rc-VWo5e4_n9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48, 48, 1).astype('float32'))\n",
        "img_array = np.stack(img_array, axis=0)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZXHV15_0yTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_array.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "rl8JYtjiyTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare training data"
      ],
      "metadata": {
        "id": "U8pt7Fgh5TBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "img_labels = le.fit_transform(df.emotion)\n",
        "img_labels = to_categorical(img_labels)\n",
        "img_labels.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "gAG5rIHtyTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(le_name_mapping)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ywgs7GAryTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data"
      ],
      "metadata": {
        "id": "dXUxSO8wz3Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(img_array, img_labels,\n",
        "                                                    shuffle=True, stratify=img_labels,\n",
        "                                                    test_size=0.1, random_state=42)\n",
        "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "v0Qv5CeNyTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df\n",
        "del img_array\n",
        "del img_labels"
      ],
      "metadata": {
        "trusted": true,
        "id": "CRKkNs4eyTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width = X_train.shape[1]\n",
        "img_height = X_train.shape[2]\n",
        "img_depth = X_train.shape[3]\n",
        "num_classes = y_train.shape[1]"
      ],
      "metadata": {
        "trusted": true,
        "id": "SjSN3QpOyTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing results, as neural networks are very sensitive to unnormalized data.\n",
        "X_train = X_train / 255.\n",
        "X_valid = X_valid / 255."
      ],
      "metadata": {
        "trusted": true,
        "id": "As-X8kjnyTHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model (Neural Network)"
      ],
      "metadata": {
        "id": "yAA36ytyz9M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_net(optim):\n",
        "    net = Sequential(name='DCNN')\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5,5),\n",
        "            input_shape=(img_width, img_height, img_depth),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_1'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_1'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=64,\n",
        "            kernel_size=(5,5),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_2'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_2'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n",
        "    net.add(Dropout(0.4, name='dropout_1'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_3'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_3'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=128,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_4'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_4'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n",
        "    net.add(Dropout(0.4, name='dropout_2'))\n",
        "\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_5'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_5'))\n",
        "    net.add(\n",
        "        Conv2D(\n",
        "            filters=256,\n",
        "            kernel_size=(3,3),\n",
        "            activation='elu',\n",
        "            padding='same',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='conv2d_6'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_6'))\n",
        "\n",
        "    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n",
        "    net.add(Dropout(0.5, name='dropout_3'))\n",
        "\n",
        "    net.add(Flatten(name='flatten'))\n",
        "\n",
        "    net.add(\n",
        "        Dense(\n",
        "            128,\n",
        "            activation='elu',\n",
        "            kernel_initializer='he_normal',\n",
        "            name='dense_1'\n",
        "        )\n",
        "    )\n",
        "    net.add(BatchNormalization(name='batchnorm_7'))\n",
        "\n",
        "    net.add(Dropout(0.6, name='dropout_4'))\n",
        "\n",
        "    net.add(\n",
        "        Dense(\n",
        "            num_classes,\n",
        "            activation='softmax',\n",
        "            name='out_layer'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    net.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=optim,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    net.summary()\n",
        "\n",
        "    return net"
      ],
      "metadata": {
        "trusted": true,
        "id": "wdJw0jAayTHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training parameters"
      ],
      "metadata": {
        "id": "jdjYyfDz0Bzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0.00005,\n",
        "    patience=11,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=7,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "]"
      ],
      "metadata": {
        "trusted": true,
        "id": "mdxQgvtFyTHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As the data in hand is less as compared to the task so ImageDataGenerator is good to go.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.15,\n",
        "    height_shift_range=0.15,\n",
        "    shear_range=0.15,\n",
        "    zoom_range=0.15,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "train_datagen.fit(X_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "w_ajnkVdyTHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 #batch size of 32 performs the best.\n",
        "epochs = 30\n",
        "optims = [\n",
        "    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n",
        "    optimizers.Adam(0.001),\n",
        "]\n",
        "\n",
        "# I tried both `Nadam` and `Adam`, the difference in results is not different but I finally went with Nadam as it is more popular.\n",
        "model = build_net(optims[1])"
      ],
      "metadata": {
        "trusted": true,
        "id": "x9TaPNR7yTHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "QXWXF2a45xZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    steps_per_epoch=len(X_train) / batch_size,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "j1eQPw8c5o7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model"
      ],
      "metadata": {
        "id": "s2psubV451tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_yaml = model.to_yaml()\n",
        "# with open(\"model.yaml\", \"w\") as yaml_file:\n",
        "#     yaml_file.write(model_yaml)\n",
        "\n",
        "# model.save(\"model.h5\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "YhK0c7jsyTHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training graphs"
      ],
      "metadata": {
        "id": "URnKFinT6IXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(12,6), facecolor=\"khaki\")\n",
        "ax[0].set_facecolor('palegoldenrod')\n",
        "ax[0].set_title('Loss', fontweight=\"bold\")\n",
        "ax[0].set_xlabel(\"Epoch\", size=14)\n",
        "ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train Loss\", color=\"navy\")\n",
        "ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation Loss\", color=\"crimson\", linestyle=\"dashed\")\n",
        "ax[0].legend()\n",
        "ax[1].set_facecolor('palegoldenrod')\n",
        "ax[1].set_title('Accuracy', fontweight=\"bold\")\n",
        "ax[1].set_xlabel(\"Epoch\", size=14)\n",
        "ax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train Acc.\", color=\"navy\")\n",
        "ax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation Acc.\", color=\"crimson\", linestyle=\"dashed\")\n",
        "ax[1].legend()"
      ],
      "metadata": {
        "id": "7GgFT8RQBN4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion matrix"
      ],
      "metadata": {
        "id": "4fHdiwb56Wcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_valid = model.predict(X_valid)"
      ],
      "metadata": {
        "id": "DrHGvVy3CDWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cm = confusion_matrix(np.argmax(y_valid, axis=1), np.argmax(yhat_valid, axis=1))\n",
        "cm_df = pd.DataFrame(cm)\n",
        "cm_df\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(cm_df, annot=True, cmap=\"Greys\", fmt=\".1f\")\n",
        "plt.title(\"Confusion Matrix\", fontweight=\"bold\")\n",
        "plt.xlabel(\"Predicted\", fontweight=\"bold\")\n",
        "plt.ylabel(\"True\", fontweight=\"bold\")"
      ],
      "metadata": {
        "id": "tPCtWzKEBbMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(np.argmax(y_valid, axis=1), np.argmax(yhat_valid, axis=1)))"
      ],
      "metadata": {
        "id": "EliUEuaQOlQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test model"
      ],
      "metadata": {
        "id": "xeFF70jT6a4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapper = {\n",
        "    0: \"happy\",\n",
        "    1: \"sad\",\n",
        "    2: \"neutral\",\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "id": "RGVR9KaOyTHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2)\n",
        "random_sad_imgs = np.random.choice(np.where(y_valid[:, 1]==1)[0], size=9)\n",
        "random_neutral_imgs = np.random.choice(np.where(y_valid[:, 2]==1)[0], size=9)\n",
        "\n",
        "fig = pyplot.figure(1, (18, 4))\n",
        "\n",
        "for i, (sadidx, neuidx) in enumerate(zip(random_sad_imgs, random_neutral_imgs)):\n",
        "        ax = pyplot.subplot(2, 9, i+1)\n",
        "        sample_img = X_valid[sadidx,:,:,0]\n",
        "        ax.imshow(sample_img, cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_title(f\"true:sad, pred:{mapper[np.argmax(model.predict(sample_img.reshape(1,48,48,1))[0])]}\")\n",
        "\n",
        "        ax = pyplot.subplot(2, 9, i+10)\n",
        "        sample_img = X_valid[neuidx,:,:,0]\n",
        "        ax.imshow(sample_img, cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        ax.set_title(f\"t:neut, p:{mapper[np.argmax(model.predict(sample_img.reshape(1,48,48,1))[0])]}\")\n",
        "\n",
        "        pyplot.tight_layout()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ABjmMG3-yTHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real time test"
      ],
      "metadata": {
        "id": "Cfdqn6qt6dej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for Capturing an image on Colab\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "trusted": true,
        "id": "SDDO7jLTyTHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Webcam photo"
      ],
      "metadata": {
        "id": "63ef7jQ-6u1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "take_photo()"
      ],
      "metadata": {
        "id": "knG2-bXn6ufn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make prediction (Webcam photo)"
      ],
      "metadata": {
        "id": "sU0kvQpR6zCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "#Testing a file.\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "file = '/content/photo.jpg'\n",
        "true_image = image.load_img(file)\n",
        "img = image.load_img(file, color_mode=\"grayscale\", target_size=(48, 48))\n",
        "\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "x /= 255\n",
        "\n",
        "custom = mapper[np.argmax(model.predict(x)[0])]\n",
        "\n",
        "x = np.array(x, 'float32')\n",
        "x = x.reshape([48, 48]);\n",
        "\n",
        "print('Prediction: ', custom)\n",
        "\n",
        "\n",
        "plt.imshow(true_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9gf0DBBo61sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3wj1T8IOtRs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}